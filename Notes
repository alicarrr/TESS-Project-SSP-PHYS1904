Want depth20/depth 120 = x 
want median(x)
y = std(x)/sqrt(n) - error of the mean 

say x +/- y

also want std(light curve 20)/ std (light curve 120) against magnitude



report - explain tess, cadences, observing strategy, important is different modes, pros and cons - explaining cadences, why is it important - reasons - new planets, making sure things haven't been chnaged poorly, why is the 20sec cadence data better? -  don't really know - better precision - onboard vs on earth processing of cosmic ray processing 

for presentations - explain transits, light curves, planet size relative to star, animation of transit -  explain cadences, tess

then ramp up the level

don't want to confuse everyone, just some people


conclusions -  what is scatter - do depths agree - do durations agree - ratio vs depth, ratio vs magnitude, are there any trends - if not - good - then processing is valid - if trends are present - interesting - what difference in precision - many many tois - individual tois - presence of extra planets - or something interesting - look at brightest ones 

set a limit to the smallest planet that could hide in the data ----> 2min vs 20sec - binned to same cadence - 20sec should have a smaller scatter at binned cadence - had a planet hiding in the noise of 2min, but since 20sec has smaller scatter - can now detect - but some planets still can hide - what is the limiting transit depth and therefore planet size for a star

pi men for example - 2 earth radius planet (he thinks)

both big sample analysis and individual systems 


sems(uncertainity)/mean/median for grouped data

what about for individual systems - injection/recovery test 

take light curve - just noise, no planet - noise case periodogram - nothing really there 

now inject a planet signal - generate a model of data with the planet added - add planet signal and noise signal - take periodogram again - can make signal smaller and smaller - can take signal to noise ratio in periodogram - keep making planet signal smaller - signal to noise vs planet radius graph - cutoff when signal to noise is below 4 - minimum planet size limit 

now repeat at different phases - different parts of light curve and repeat - and see distribution of limit 

measure scatter - standard deviation - 120 sec vs 20 sec - bin 20 to 120 and take stdev of noise (remove transit)

beyond snow line in order to get enougb mass for a core bc of ice, and dust (needs to be cold enough) - then everything else comes in - gases -  for jupiter masses - 10+ earth radius


take depth 0.05 and greater - bc individual offset below that goes over the systenatic offset (ratio) - can't measure the scatters well enough to distinguish 

weve mmeasured a 1-2 percent offset - but is it signficant? at lower depth no bc the individual error in the plots is bigegr than that offset - we can't tell if its the random error at lower depths 

e.g if systematic at 0.5, and random at 0.1 -  we can measure random precisely, but if that random precision is way biggr (e.g small depth) we cant tell if the syustematic is a result of the random error

at the larger depths we can tell and have a significant result 

take in transit (flat bottom) data (std) and divide by number of points for the individual error

depth vs the calculated value above (ratio of - error / depth) ==  relative error

find percent error in individual vs percent error in median/sem/collective


ask dan about injection recovery - meaasuring signal to noise ratio - how to do it?  - use bls - if max period/average noise > 4 its good - average across different sections 

toi 573 is an interesting one - big depth - good difference in scatter 

measurement error - numerical justification + visually 

presentation:
5 +5 +5
intro and motivations -  tess, why, what, 20 vs 120, cadence, data processing, cosmic ray rejection (onboard, vs on earth -  the way they reject the rays)
methods - individual transits, how we did it, then iterating 
results - 


